{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INTRODUCTION\n",
    "\n",
    "- Data can be present in different ways.\n",
    "- Types of data variables present in this data:\n",
    "    - **Binary data** : A binary variable a variable that has only 2 values..ie 0/1\n",
    "    - **Categorical data** : A categorical variable is a variable that can take some limited number of values.for example,day of the week.It can be one of 1,2,3,4,5,6,7 only.\n",
    "    - **Ordinal data** : An ordinal variable is a categorical variable that has some order associated with it.for example,the ratings that are given to a movie by a user.\n",
    "    - **Nominal data** : Nominal value is a variable that has no numerical importance,such as occupation,person name etc..\n",
    "    - **Timeseries data** : Time series data has a temporal value attached to it, so this would be something like a date or a time stamp that you can look for trends in time.\n",
    "![Label Encoding](https://techmintz.com/wp-content/uploads/2019/12/0*emSbyTsSeHaeFUKc-780x520.jpeg)\n",
    "--- \n",
    "### Why do we need Label Encoding ?\n",
    "\n",
    "- For example, a decision tree can be learned directly from categorical data with no data transform required (this depends on the specific implementation).\n",
    "\n",
    "- Many machine learning algorithms cannot operate on label data directly. They require all input variables and output variables to be numeric.\n",
    "\n",
    "- In general, this is mostly a constraint of the efficient implementation of machine learning algorithms rather than hard limitations on the algorithms themselves.\n",
    "\n",
    "- This means that categorical data must be converted to a numerical form. If the categorical variable is an output variable, you may also want to convert predictions by the model back into a categorical form in order to present them or use them in some application.\n",
    "--- \n",
    "- In this notebook we will try some of the most commonly used encoding techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading dataset from Kaggle using Kaggle API\n",
    "- First, get kaggle.json file from your kaggle account and upload to gdrive.\n",
    "- Second, Call Kaggle api to download the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "bxcJVYgbtXwh",
    "outputId": "ee548ad7-7916-4f87-abb1-0fb5fc75dce6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-9e6b332c-c7d8-4c24-99ff-1cb943bd4d32\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-9e6b332c-c7d8-4c24-99ff-1cb943bd4d32\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n",
      "User uploaded file \"kaggle.json\" with length 69 bytes\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded  = files.upload()\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))\n",
    "\n",
    "# Then move kaggle.json into the folder where the API expects to find it.\n",
    "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "eefp_s6xt0iX",
    "outputId": "64a9765a-41d4-4822-e2ee-20985929d1cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
      "Downloading sample_submission.csv.zip to /content\n",
      "  0% 0.00/436k [00:00<?, ?B/s]\n",
      "100% 436k/436k [00:00<00:00, 59.5MB/s]\n",
      "Downloading train.csv.zip to /content\n",
      " 40% 5.00M/12.5M [00:00<00:00, 27.4MB/s]\n",
      "100% 12.5M/12.5M [00:00<00:00, 49.7MB/s]\n",
      "Downloading test.csv.zip to /content\n",
      " 60% 5.00M/8.28M [00:00<00:00, 35.0MB/s]\n",
      "100% 8.28M/8.28M [00:00<00:00, 52.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c cat-in-the-dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "LLlyckhcuDaH",
    "outputId": "783e3213-c1ff-45bf-8805-8a3af8e7baac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  test.csv.zip\n",
      "  inflating: test.csv                \n",
      "Archive:  train.csv.zip\n",
      "  inflating: train.csv               \n"
     ]
    }
   ],
   "source": [
    "!unzip test.csv.zip\n",
    "!unzip train.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J0lM7j52uNa2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zPn10UY9uaPb"
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('/content/train.csv')\n",
    "df_test=pd.read_csv('/content/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "jJhbKl-9uiNq",
    "outputId": "3225ddc8-6778-4e55-83b4-de4299acc826"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data set has got 300000 rows and 25 columns\n",
      "test data set has got 200000 rows and 24 columns\n"
     ]
    }
   ],
   "source": [
    "print('train data set has got {} rows and {} columns'.format(df_train.shape[0],df_train.shape[1]))\n",
    "print('test data set has got {} rows and {} columns'.format(df_test.shape[0],df_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "nehIi6ptunSv",
    "outputId": "cd1b7f15-fbf0-4379-859a-526da518a8c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>nom_4</th>\n",
       "      <th>nom_5</th>\n",
       "      <th>nom_6</th>\n",
       "      <th>nom_7</th>\n",
       "      <th>nom_8</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Green</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Bassoon</td>\n",
       "      <td>50f116bcf</td>\n",
       "      <td>3ac1b8814</td>\n",
       "      <td>68f6ad3e9</td>\n",
       "      <td>c389000ab</td>\n",
       "      <td>2f4cb3d51</td>\n",
       "      <td>2</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>h</td>\n",
       "      <td>D</td>\n",
       "      <td>kr</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Green</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Piano</td>\n",
       "      <td>b3b4d25d0</td>\n",
       "      <td>fbcb50fc1</td>\n",
       "      <td>3b6dd5612</td>\n",
       "      <td>4cd920251</td>\n",
       "      <td>f83c56c21</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Hot</td>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>bF</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Theremin</td>\n",
       "      <td>3263bdce5</td>\n",
       "      <td>0922e3cb8</td>\n",
       "      <td>a6a36f527</td>\n",
       "      <td>de9c9f684</td>\n",
       "      <td>ae6800dd0</td>\n",
       "      <td>1</td>\n",
       "      <td>Expert</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>h</td>\n",
       "      <td>R</td>\n",
       "      <td>Jc</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Oboe</td>\n",
       "      <td>f12246592</td>\n",
       "      <td>50d7ad46a</td>\n",
       "      <td>ec69236eb</td>\n",
       "      <td>4ade6ab69</td>\n",
       "      <td>8270f0d71</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>i</td>\n",
       "      <td>D</td>\n",
       "      <td>kW</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Oboe</td>\n",
       "      <td>5b0f5acd5</td>\n",
       "      <td>1fe17a1fd</td>\n",
       "      <td>04ddac2be</td>\n",
       "      <td>cb43ab175</td>\n",
       "      <td>b164b72a7</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>a</td>\n",
       "      <td>R</td>\n",
       "      <td>qP</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  bin_0  bin_1  bin_2 bin_3 bin_4  ... ord_3 ord_4 ord_5 day month target\n",
       "0   0      0      0      0     T     Y  ...     h     D    kr   2     2      0\n",
       "1   1      0      1      0     T     Y  ...     a     A    bF   7     8      0\n",
       "2   2      0      0      0     F     Y  ...     h     R    Jc   7     2      0\n",
       "3   3      0      1      0     F     Y  ...     i     D    kW   2     1      1\n",
       "4   4      0      0      0     F     N  ...     a     R    qP   7     8      0\n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rk0MfFa_u2yx"
   },
   "source": [
    "## Defining Training data and Target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sKPkZdghu_KS"
   },
   "outputs": [],
   "source": [
    "X=df_train.drop(['target'],axis=1)\n",
    "y=df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "B9u3ftrdvEps",
    "outputId": "d3aceca0-6cd9-4c09-ee0f-2dae2fe50a5e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEICAYAAABBBrPDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=y.value_counts()\n",
    "plt.bar(x.index,x)\n",
    "plt.gca().set_xticks([0,1])\n",
    "plt.title('distribution of target variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlHR_RMtvf_1"
   },
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x48ZimLtvj5z"
   },
   "source": [
    "### Method 1: Label encoding\n",
    "- In this method we change every categorical data to a number\n",
    "- That is each type will be replaced by a number\n",
    "- For example we will substitute 1 for Grandmaster,2 for master ,3 for expert etc.. For implementing this we will first import Labelencoder from sklearn module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "wqv_rdCovYlP",
    "outputId": "d983ea9a-52a3-430a-f69f-f59b565bb8bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 863 ms, sys: 27.8 ms, total: 891 ms\n",
      "Wall time: 892 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "train=pd.DataFrame()\n",
    "label=LabelEncoder()\n",
    "for c in  X.columns:\n",
    "    if(X[c].dtype=='object'):\n",
    "        train[c]=label.fit_transform(X[c])\n",
    "    else:\n",
    "        train[c]=X[c]\n",
    "        \n",
    "train.head(3)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YtAnm-dKwN8x"
   },
   "source": [
    "\n",
    "\n",
    "- Here you can see the label encoded output train data.We will check the shape of train data now and verify that there is no change in the number of columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "08BvyUMWwDlI",
    "outputId": "d385fdb4-f1a8-4a3f-ca2f-4a6e29927a86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data set has got 300000 rows and 24 columns\n"
     ]
    }
   ],
   "source": [
    "print('train data set has got {} rows and {} columns'.format(train.shape[0],train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mn9iLXGUwckj"
   },
   "source": [
    "#### Logistic Regression:\n",
    "- We will use logistic regression to predict the target label on label encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8zjWLwPworz"
   },
   "outputs": [],
   "source": [
    "def logistic(X,y):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42,test_size=0.2)\n",
    "    lr=LogisticRegression()\n",
    "    lr.fit(X_train,y_train)\n",
    "    y_pre=lr.predict(X_test)\n",
    "    print('Accuracy : ',accuracy_score(y_test,y_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-CQeyci_wuN-",
    "outputId": "49501432-f575-47ac-889e-0d2bccbf2cc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.69065\n"
     ]
    }
   ],
   "source": [
    "logistic(train,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dph0LjIIw0G9"
   },
   "source": [
    "### Method 2 : On hot encoding\n",
    "- This type of encoding converts each category as a one hot encoding (OHE) vector (or dummy variables). OHE is a representation method that takes each category value and turns it into a binary vector of size |i|(number of values in category i) where all columns are equal to zero besides the category column. \n",
    "- Here is a little example:\n",
    "![One Hot Encoding](https://miro.medium.com/max/878/1*WXpoiS7HXRC-uwJPYsy1Dg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "MM-fpuq8xaiR",
    "outputId": "2f842ec0-3f26-4968-8f80-9ceb01cd1df3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data set has got 300000 rows and 316461 columns\n",
      "CPU times: user 1.49 s, sys: 31.8 ms, total: 1.52 s\n",
      "Wall time: 1.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "one=OneHotEncoder()\n",
    "one.fit(X)\n",
    "train=one.transform(X)\n",
    "\n",
    "print('train data set has got {} rows and {} columns'.format(train.shape[0],train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "dP8wCkOIxrYk",
    "outputId": "6a3412a3-fd1b-4957-c033-61ec56b1ea53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.75715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logistic(train,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "60m_ZmNvyI62"
   },
   "source": [
    "### Method 3 : Feature hashing (hashing trick)\n",
    "\n",
    "- Feature hashing is a very cool technique to represent categories in a “one hot encoding style” as a sparse matrix but with a much lower dimensions. \n",
    "- In feature hashing we apply a hashing function to the category and then represent it by its indices. \n",
    "- For example, if we choose a dimension of 5 to represent “New York” we will calculate H(New York) mod 5 = 3 (for example) so New York representation will be (0,0,1,0,0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "_ip5RsoQysEU",
    "outputId": "01321aa5-e38d-406e-b69b-a0db0d760e72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.08 s, sys: 63.6 ms, total: 4.14 s\n",
      "Wall time: 4.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "\n",
    "\n",
    "X_train_hash=X.copy()\n",
    "for c in X.columns:\n",
    "    X_train_hash[c]=X[c].astype('str')      \n",
    "hashing=FeatureHasher(input_type='string')\n",
    "train=hashing.transform(X_train_hash.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BA7JbalVy0wW",
    "outputId": "b9b7a733-4dd2-4e9d-a01d-a978f5bc9196"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data set has got 300000 rows and 1048576 columns\n"
     ]
    }
   ],
   "source": [
    "print('train data set has got {} rows and {} columns'.format(train.shape[0],train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "-s2my9DLy4_F",
    "outputId": "041b27cb-7a89-4c6d-ac9c-9d84ca1b92ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.7516833333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logistic(train,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "onh80Y8Oy_lB"
   },
   "source": [
    "### Method 4 : Encoding categories with dataset statistic\n",
    "\n",
    "- Now we will try to give our models a numeric representation for every category with a small number of columns but with an encoding that will put similar categories close to each other. \n",
    "- The easiest way to do it is replace every category with the number of times that we saw it in the dataset. \n",
    "- This way if New York and New Jersey are both big cities, they will probably both appear many times in our dataset and the model will know that they are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "2CLEnghezRq6",
    "outputId": "3687faca-db57-4c22-b6f5-41a201f13cc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 562 ms, sys: 14.3 ms, total: 576 ms\n",
      "Wall time: 596 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train_stat=X.copy()\n",
    "for c in X_train_stat.columns:\n",
    "    if(X_train_stat[c].dtype=='object'):\n",
    "        X_train_stat[c]=X_train_stat[c].astype('category')\n",
    "        counts=X_train_stat[c].value_counts()\n",
    "        counts=counts.sort_index()\n",
    "        counts=counts.fillna(0)\n",
    "        counts += np.random.rand(len(counts))/1000\n",
    "        X_train_stat[c].cat.categories=counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "id": "KuLuGS7KzcE9",
    "outputId": "88d677a9-65d0-48f1-8810-c6a1f8a88133"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>nom_4</th>\n",
       "      <th>nom_5</th>\n",
       "      <th>nom_6</th>\n",
       "      <th>nom_7</th>\n",
       "      <th>nom_8</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153535.000307</td>\n",
       "      <td>191633.000349</td>\n",
       "      <td>127341.000613</td>\n",
       "      <td>29855.000407</td>\n",
       "      <td>45979.000524</td>\n",
       "      <td>36942.000669</td>\n",
       "      <td>68448.000619</td>\n",
       "      <td>2594.000460</td>\n",
       "      <td>1148.000100</td>\n",
       "      <td>241.000134</td>\n",
       "      <td>271.000419</td>\n",
       "      <td>19.000890</td>\n",
       "      <td>2</td>\n",
       "      <td>77428.000840</td>\n",
       "      <td>33768.000056</td>\n",
       "      <td>24740.000813</td>\n",
       "      <td>3974.000743</td>\n",
       "      <td>506.000402</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>153535.000307</td>\n",
       "      <td>191633.000349</td>\n",
       "      <td>127341.000613</td>\n",
       "      <td>101181.000097</td>\n",
       "      <td>29487.000694</td>\n",
       "      <td>101123.000021</td>\n",
       "      <td>84517.000418</td>\n",
       "      <td>792.000803</td>\n",
       "      <td>842.000982</td>\n",
       "      <td>287.000052</td>\n",
       "      <td>111.000134</td>\n",
       "      <td>13.000259</td>\n",
       "      <td>1</td>\n",
       "      <td>77428.000840</td>\n",
       "      <td>22227.000246</td>\n",
       "      <td>35276.000920</td>\n",
       "      <td>18258.000000</td>\n",
       "      <td>2603.000699</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>146465.000435</td>\n",
       "      <td>191633.000349</td>\n",
       "      <td>96166.000929</td>\n",
       "      <td>101181.000097</td>\n",
       "      <td>101295.000356</td>\n",
       "      <td>101123.000021</td>\n",
       "      <td>54742.000541</td>\n",
       "      <td>2524.000536</td>\n",
       "      <td>1169.000602</td>\n",
       "      <td>475.000152</td>\n",
       "      <td>278.000688</td>\n",
       "      <td>29.000682</td>\n",
       "      <td>1</td>\n",
       "      <td>25065.000477</td>\n",
       "      <td>63908.000183</td>\n",
       "      <td>24740.000813</td>\n",
       "      <td>16927.000531</td>\n",
       "      <td>2572.000440</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  bin_0  bin_1  bin_2  ...         ord_4        ord_5 day month\n",
       "0   0      0      0      0  ...   3974.000743   506.000402   2     2\n",
       "1   1      0      1      0  ...  18258.000000  2603.000699   7     8\n",
       "2   2      0      0      0  ...  16927.000531  2572.000440   7     2\n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_stat.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KMaTBZYVzhkr",
    "outputId": "f8a00147-fe78-4a36-c046-dc5bd58eb99f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data set has got 300000 rows and 24 columns\n"
     ]
    }
   ],
   "source": [
    "print('train data set has got {} rows and {} columns'.format(X_train_stat.shape[0],X_train_stat.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "ZafG7HDXzovY",
    "outputId": "b3c4bfcb-9049-4cf0-e601-7a6ad3214ec6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.6946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logistic(X_train_stat,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sC4iKmFCz0o0"
   },
   "source": [
    "### Encoding cyclic features\n",
    "\n",
    "![cyclic features encoding](https://miro.medium.com/max/343/1*70cevmU8wNggGJEdLam1lw.png)\n",
    "\n",
    "- Some of our features are cyclic in nature.ie day,month etc.\n",
    "\n",
    "- A common method for encoding cyclical data is to transform the data into two dimensions using a sine and consine transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "8GzpR4NS0JEW",
    "outputId": "2cbc18ad-c65d-4354-9315-a573b3579ca2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 256 ms, sys: 1.74 ms, total: 258 ms\n",
      "Wall time: 254 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train_cyclic=X.copy()\n",
    "columns=['day','month']\n",
    "for col in columns:\n",
    "    X_train_cyclic[col+'_sin']=np.sin((2*np.pi*X_train_cyclic[col])/max(X_train_cyclic[col]))\n",
    "    X_train_cyclic[col+'_cos']=np.cos((2*np.pi*X_train_cyclic[col])/max(X_train_cyclic[col]))\n",
    "X_train_cyclic=X_train_cyclic.drop(columns,axis=1)\n",
    "\n",
    "X_train_cyclic[['day_sin','day_cos']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XjNmojIU0w86"
   },
   "source": [
    "- Now we will use OnHotEncoder to encode other variables,then feed the data to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z59OPXRy02uH",
    "outputId": "87692bcd-d977-4fab-dd19-b7d0e4f8410f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data set has got 300000 rows and 316478 columns\n"
     ]
    }
   ],
   "source": [
    "one=OneHotEncoder()\n",
    "\n",
    "one.fit(X_train_cyclic)\n",
    "train=one.transform(X_train_cyclic)\n",
    "\n",
    "print('train data set has got {} rows and {} columns'.format(train.shape[0],train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "r7PUf9QN0-mP",
    "outputId": "aaa98bf9-8577-4917-b7d7-64f555d3b9fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logistic(train,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "StyLH90P1G4P"
   },
   "source": [
    "### Method 5 : Target encoding\n",
    "\n",
    "- Target-based encoding is numerization of categorical variables via target. \n",
    "- In this method, we replace the categorical variable with just one new numerical variable and replace each category of the categorical variable with its corresponding probability of the target (if categorical) or average of the target (if numerical). \n",
    "- The main drawbacks of this method are its dependency to the distribution of the target, and its lower predictability power compare to the binary encoding method.\n",
    "\n",
    "- For example,\n",
    "\n",
    "| Country | Target |\n",
    "| --- | --- | \n",
    "| India  | 1 | \n",
    "| China | 0 | \n",
    "| India | 0 | \n",
    "| China | 1 | \n",
    "| India | 1 | \n",
    "\n",
    "- Encoding for India = [Number of true targets under the label India/ Total Number of targets under the label India] which is 2/3 = 0.66\n",
    "\n",
    "| Country | Target |\n",
    "| --- | --- | \n",
    "| India  | 0.66 | \n",
    "| China | 0.5 | \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Z2C5x5n72eCd",
    "outputId": "56fcdb54-ebc1-4111-8eb1-2f1d201e1d8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 24s, sys: 48.7 s, total: 3min 13s\n",
      "Wall time: 3min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_target=df_train.copy()\n",
    "X_target['day']=X_target['day'].astype('object')\n",
    "X_target['month']=X_target['month'].astype('object')\n",
    "for col in X_target.columns:\n",
    "    if (X_target[col].dtype=='object'):\n",
    "        target= dict ( X_target.groupby(col)['target'].agg('sum')/X_target.groupby(col)['target'].agg('count'))\n",
    "        X_target[col]=X_target[col].replace(target).values\n",
    "        \n",
    "X_target.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "L8-yJLsu6Ja2",
    "outputId": "04eaacd5-41ac-41dc-c49c-bb20c916e1cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.6946166666666667\n"
     ]
    }
   ],
   "source": [
    "logistic(X_target.drop('target',axis=1),y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wI4YbJ1mbAnT"
   },
   "source": [
    "### Summary - \n",
    "\n",
    "- Here you can see the summary of our model performance against each of the encoding techniques we have used. \n",
    "- It is clear that OnHotEncoder together with cyclic feature encoding yielded maximum accuracy.\n",
    "\n",
    "\n",
    "| ENCODING | SCORE | WALLTIME |\n",
    "| --- | --- | --- |\n",
    "|Label Encoding\t|0.692\t|892 ms|\n",
    "|OnHotEncoder\t|0.759\t|1.52 s|\n",
    "|Feature Hashing|\t0.751\t|4.16 s|\n",
    "|Dataset statistic encoding\t|0.694\t|596 ms|\n",
    "|Cyclic + OnHotEncoding\t|0.759|\t254 ms|\n",
    "|Target encoding|\t0.694\t|3min 13s|\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Label_Encoding_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
